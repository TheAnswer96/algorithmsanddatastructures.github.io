<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Algorithms and Data Structures: A Premise</title>
    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha3/dist/css/bootstrap.min.css" rel="stylesheet">
    <!-- External Google Fonts for futuristic and minimalist fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700&family=Lato:wght@300;400&family=Roboto:wght@300;400&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="css/styles.css">
</head>
<body>

     <header class="text-center my-5">
        <h1 class="display-4">Algorithms and Data Structures: A Premise</h1>
    </header>

    <main class="container">
        <!-- Introduction Section -->
        <section id="introduction" class="mb-5">
                <h2 class="h2 mb-3">Introduction</h2>
            <p class="lead">
                Data structures and algorithms are fundamental components of computer science and software development, playing a crucial role in solving complex problems efficiently.
                By understanding the importance of data structures and algorithms, programmers and developers can enhance their problem-solving abilities, optimize resource utilization, and create more efficient and scalable software.
            </p>

            <p class="lead">
                Data structures refer to the organization and storage of data in a computer’s memory, while algorithms are a set of instructions or rules that manipulate and process that data.
                These two concepts are intertwined and form the backbone of software engineering. Data structures provide a way to store and organize data, enabling efficient access, modification, and retrieval, while algorithms define the steps and procedures to perform various operations on the stored data.
            </p>

            <p class="lead">
                Donald Knuth defines an algorithm as a set of steps, or rules, with five basic properties:
                <ul>
                    <li class="lead">
                        <strong>Finiteness</strong> - An algorithm must start and stop. The rules an algorithm applies must also conclude in a reasonable amount of time. What “reasonable” is depends on the nature of the algorithm, but in no case can an algorithm take an infinite amount of time to complete its task.
                        Knuth calls this property the finiteness of an algorithm.
                    </li>
                    <li class="lead">
                        <strong>Definiteness</strong>  - The actions that an algorithm performs cannot be open to multiple interpretations; each step must be precise and unambiguous. Knuth terms this quality definiteness. An algorithm cannot iterate a “bunch” of times. The number of times must be precisely expressed, for example 2, 1000000, or a randomly chosen number.
                    </li>
                    <li class="lead">
                        <strong>Inputs</strong>- An algorithm starts its computation from an initial state. This state may be expressed as input values given to the algorithm before it starts.
                    </li>
                    <li class="lead">
                        <strong>Outputs</strong>- An algorithm must produces a result with a specific relation to the inputs.
                    </li>
                    <li class="lead">
                        <strong>Effectiveness</strong>  - The steps an algorithm takes must be sufficiently simple that they could be expressed “on paper”; these steps must make sense for the quantities used. Knuth terms this property effectiveness.
                        So for the example above of getting to work in the morning, the algorithm is considered finite because it will eventually end when I reach work. It is definite because each step can be followed exactly. The inputs include: my kids, the bus, myself, etc… The output is that I arrive at work. And the algorithm is considered effective because the steps can be listed for you to read and understand.
                    </li>
                </ul>
            </p>

            <h3>Enhances Problem-Solving Skills</h3>

            <p class="lead">
                Data structures and algorithms provide a systematic approach to problem-solving.
                They enable programmers to break down complex problems into smaller, more manageable components, allowing for step-by-step analysis and efficient implementation.
                By understanding different data structures and algorithms, developers can choose the most appropriate approach to solve a particular problem, leading to optimized solutions.
            </p>

            <h3>Optimizes Resource Utilization</h3>

            <p class="lead">
                Efficient resource utilization is essential in software development.
                Data structures and algorithms help manage memory and computational resources effectively.
                Well-designed data structures ensure that data is stored and accessed in the most optimized way, reducing memory usage and improving overall performance.
                Additionally, algorithms provide techniques to process and manipulate data with minimal computational overhead.
            </p>

            <h3>Improves Code Efficiency</h3>

            <p class="lead">
                Data structures and algorithms impact the efficiency of code.
                By choosing the appropriate data structure for a specific problem, developers can reduce the time and computational resources required for operations such as searching, sorting, and inserting data.
                Similarly, well-optimized algorithms can significantly improve code efficiency, resulting in faster and more responsive software.
            </p>

            <h3>Facilitates Scalability and Flexibility</h3>

            <p class="lead">
                As software systems grow in complexity, the ability to scale and adapt becomes crucial.
                Data structures and algorithms play a vital role in enabling scalability and flexibility in software development.
                By using scalable data structures, developers can accommodate larger datasets and handle increased user loads without sacrificing performance.
            </p>

             <figure class="text-center">
                <img src="images/l1_funny.jpg" class="img-fluid w-25 rounded shadow-sm">
                <figcaption class="text-muted mt-3">Time Complexity Relevance: A Funny Picture.</figcaption>
            </figure>

            <h2>Real-World Applications of Data Structures and Algorithms</h2>

            <p class="lead">
                Algorithms and data structures are everywhere in our nowdays lifes.
                You can find them even inside everyday activities.
            </p>

            <figure class="text-center">
                <img src="images/l1_funny2.jpg" class="img-fluid w-25 rounded shadow-sm">
                <figcaption class="text-muted mt-3">Algorithms and Data Structures Everywhere.</figcaption>
            </figure>

            <p class="lead">
                The impact of data structures and algorithms can be seen in various real-world applications.
                Some notable examples include:
            </p>

            <h3>Search Engines</h3>

            <p class="lead">
                Search engines like Google rely heavily on data structures and algorithms to efficiently index and retrieve vast amounts of information.
                Algorithms like PageRank determine the relevance and ranking of web pages, while data structures such as inverted indexes enable quick keyword-based searches.
            </p>

            <figure class="text-center">
                <img src="images/l1_example1.png" class="img-fluid w-25 rounded shadow-sm">
                <figcaption class="text-muted mt-3">Searching Engine Optimization.</figcaption>
            </figure>

            <h3>Social Networks</h3>

            <p class="lead">
                Social networking platforms like Facebook and Twitter handle massive amounts of user-generated content.
                Data structures like graphs facilitate efficient friend connections and recommendations, while algorithms for news feed generation prioritize relevant and engaging content for users.
            </p>

            <figure class="text-center">
                <img src="images/l1_example2.png" class="img-fluid w-25 rounded shadow-sm">
                <figcaption class="text-muted mt-3">Social Network Advertisement Suggestions.</figcaption>
            </figure>

            <h3>Navigation Systems</h3>

            <p class="lead">
                Google Maps navigation systems employ data structures and algorithms to calculate the fastest or shortest routes between destinations.
                Graph-based algorithms, such as Dijkstra’s algorithm, are used to find optimal paths, while spatial data structures help store and retrieve location-based information.
            </p>

            <figure class="text-center">
                <img src="images/l1_example3.jpg" class="img-fluid w-25 rounded shadow-sm">
                <figcaption class="text-muted mt-3">Google Maps Fastest Route Computation.</figcaption>
            </figure>
        </section>

        <!-- Start with an example Section -->
        <section id="max-subarray" class="mb-5">
            <h2 class="h2 mb-3">Break the Ice with an Example</h2>
            <p class="lead">
                The <strong>Maximum Subarray Sum</strong> problem is a classic algorithm problem where, given an array of integers,
                we are tasked with finding the contiguous subarray (containing at least one number) which has the largest sum.
                This problem often appears in coding interviews and algorithm courses due to its elegant solution using
                dynamic programming.
            </p>

            <p class="lead">
                Imagine we are given an array of numbers. Our goal is to find the subarray with the maximum possible sum.
                The key challenge is that the array can contain negative numbers, making it harder to just select
                the largest values. Let's look at some examples to visualize this better.
            </p>

            <div class="example-container mb-4">
                <div class="example">
                    <p class="text-center">Array: <code>[-2, 1, -3, 4, -1, 2, 1, -5, 4]</code></p>
                    <p class="text-center">Maximum Subarray: <strong>[4, -1, 2, 1]</strong></p>
                    <p class="text-center">Maximum Sum: <strong>6</strong></p>
                </div>
            </div>

            <div class="example-container mb-4">
                <div class="example">
                    <p class="text-center">Array: <code>[1, -2, 3, 5, -3, 7, -2]</code></p>
                    <p class="text-center">Maximum Subarray: <strong>[3, 5, -3, 7]</strong></p>
                    <p class="text-center">Maximum Sum: <strong>12</strong></p>
                </div>
            </div>

            <div class="example-container mb-4">
                <div class="example">
                    <p class="text-center">Array: <code>[-5, -1, -8, -9]</code></p>
                    <p class="text-center">Maximum Subarray: <strong>[-1]</strong></p>
                    <p class="text-center">Maximum Sum: <strong>-1</strong></p>
                </div>
            </div>
        </section>

        <section id="brute-force" class="mb-5">
            <h3 class="h3 mb-3">Brute Force Solution</h3>
            <p class="lead">
                The brute force solution for the Maximum Subarray Sum problem involves systematically checking all possible subarrays
                and calculating their sums to find the maximum sum. Though simple, it is inefficient with a time complexity of O(n²).
            </p>

            <!-- Input vector visualization -->
            <div class="example-container mb-4 text-center">
                <p>Input Vector:</p>
                <div id="input-vector" class="vector-display"></div>
            </div>

            <!-- Maximum sum and indices information -->
            <div class="example-container mb-4 text-center">
                <p>From Index: <strong><span id="max-start"></span></strong> to Index: <strong><span id="max-end"></span></strong></p>
                <p>Maximum Sum: <strong><span id="output-max-sum"></span></strong></p>
            </div>

            <!-- Controls -->
            <div class="controls mb-3 text-center">
                <label for="delay">Delay (ms): </label>
                <input type="number" id="delay" min="100" value="500" class="form-control-inline">
                <button id="start" class="btn btn-primary">Start Execution</button>
                <button id="restart" class="btn btn-secondary">Regenerate Vector</button>
            </div>
        </section>

        <section id="divide-and-conquer" class="mb-5">
            <h3 class="h3 mb-3">Divide and Conquer Solution</h3>
            <p class="lead">
                The Divide and Conquer approach splits the array into two halves, recursively finds the maximum subarray in both halves,
                and checks the middle subarray crossing the two halves. This method reduces the time complexity to O(n log n).
            </p>

            <!-- Input vector visualization -->
            <div class="example-container mb-4 text-center">
                <p>Input Vector:</p>
                <div id="input-vector-dnc" class="vector-display"></div>
            </div>

            <!-- Maximum sum and indices information -->
            <div class="example-container mb-4 text-center">
                <p>From Index: <strong><span id="max-start-dnc"></span></strong> to Index: <strong><span id="max-end-dnc"></span></strong></p>
                <p>Maximum Sum: <strong><span id="output-max-sum-dnc"></span></strong></p>
            </div>

            <!-- Controls -->
            <div class="controls mb-3 text-center">
                <label for="delay-dnc">Delay (ms): </label>
                <input type="number" id="delay-dnc" min="100" value="500" class="form-control-inline">
                <button id="start-dnc" class="btn btn-primary">Start Execution</button>
                <button id="restart-dnc" class="btn btn-secondary">Regenerate Vector</button>
            </div>
        </section>

        <section id="dynamic-programming" class="mb-5">
            <h3 class="h3 mb-3">Dynamic Programming Solution</h3>
            <p class="lead">
                The Dynamic Programming approach for the Maximum Subarray problem builds a solution incrementally.
                By maintaining a running sum and comparing it with the current element, we can determine the maximum subarray ending at each position.
                This approach reduces the time complexity to O(n).
            </p>

            <!-- Input vector visualization -->
            <div class="example-container mb-4 text-center">
                <p>Input Vector:</p>
                <div id="input-vector-dp" class="vector-display"></div>
            </div>

            <!-- Maximum sum and indices information -->
            <div class="example-container mb-4 text-center">
                <p>From Index: <strong><span id="max-start-dp"></span></strong> to Index: <strong><span id="max-end-dp"></span></strong></p>
                <p>Maximum Sum: <strong><span id="output-max-sum-dp"></span></strong></p>
            </div>

            <!-- Controls -->
            <div class="controls mb-3 text-center">
                <label for="delay-dp">Delay (ms): </label>
                <input type="number" id="delay-dp" min="100" value="500" class="form-control-inline">
                <button id="start-dp" class="btn btn-primary">Start Execution</button>
                <button id="restart-dp" class="btn btn-secondary">Regenerate Vector</button>
            </div>
        </section>

        <section id="introduction" class="mb-5">
                <h2 class="h2 mb-3">Running Time</h2>
            <p class="lead">
                Most algorithms transform input objects into output objects.​
                The running time of an algorithm typically grows with the input size.​
                <!-- Since average case time is often difficult to determine, we focus primarily on the worst case running time because is easier to analyze​ but mostly because it is crucial to applications such as games, finance and robotics​. -->
            </p>

            <p class="lead">
                In order to dig into the beauty and challenges that pertain with its ideation and design, we need to start from the concept of <strong>execution time</strong>.
                In this case, the straigthforward idea is to run our program with inputs of varying size and composition, noting the running time required.
            </p>

            <div class="example-container mb-4">
                <div class="example">
                    <p class="text-left"><b>long</b> startTime = System.currentTimeMillis(); </code></p>
                    <p class="text-left"><strong><i>   your long algorithm...</i></strong></p>
                    <p class="text-left"><b>long</b> endTime = System.currentTimeMillis();</p>
                    <p class="text-left"><b>long</b> elapsedTime = endTime - startTime;</p>
                </div>
            </div>

            <div class="container text-center">
                <h2>Algorithm Maximum subarray</h2>
                <canvas id="plotCanvas" width="400" height="400"></canvas><br>
                <button id="plotButton" class="btn btn-primary">Measure Running Time</button>
            </div>

            <p class="lead">
                However, there are challenges that cannot be neglected:
                <ul>
                    <li class="lead">
                        Experimental running times of two algorithms are difficult to directly compare unless the experiments are performed in the same hardware and software environments.
                    </li>
                    <li class="lead">
                        Experiments can be done only on a limited set of test inputs; hence, they leave out the running times of inputs not included in the experiment (and these inputs may be important).
                    </li>
                    <li class="lead">
                        An algorithm must be fully implemented in order to execute it to study its running time experimentally.
                    </li>
                </ul>
            </p>

            <h3 class="h3 mb-3">Theoretical Analysis</h3>
            <p class="lead">
                To evaluate and compare different algorithms, instead of looking at the actual runtime for an algorithm, it makes more sense to use something called <strong>time complexity</strong>.
                Time complexity is more abstract than actual runtime, and does not consider factors such as programming language or hardware.
                Time complexity is the number of operations needed to run an algorithm on large amounts of data. And the number of operations can be considered as time because the computer uses some time for each operation.
                For example, in the algorithm that finds the maximum sum subarray, each value in the array must be seen one time.
                Every such comparison can be considered an operation, and each operation takes a certain amount of time.
                So the total time the algorithm needs to find the maximum sum subarray depends on the number of values in the array.
                The time it takes to find the maximum sum subarray is therefore linear with the number of values.
                Roughly speaking, 100 values results in 100 comparisons, and 5000 values results in 5000 comparisons.
            </p>

            <p class="lead">
                In other words, we want to use a high-level description of the algorithm instead of an implentation, characterizing the running time as a function of the input size.
                In this way, we take into account all possible inputs, evaluating the speed of an algorithm independent of the hardware/software environment.
            </p>

            <h3 class="h3 mb-3">"One Operation"</h3>
            <p class="lead">
                Two common tools used for algorithm analysis are the RAM model of computation and the asymptotic analysis of worst-case complexity.
                The <strong>RAM</strong> (Random Access Machine) model is used for analyzing algorithms without running them on a physical machine.
                <br>
                The RAM model has the following properties:
                <ul>
                    <li class="lead">
                        A simple operation (+, \, *, -, =, if) takes one time step.
                    </li>
                    <li class="lead">
                        Loops and subroutines are comprised of simple operations.
                    </li>
                    <li class="lead">
                        Memory is unlimited and access takes one time step (the RAM model does not consider whether data is on cache or disk).
                    </li>
                </ul>
                Using the RAM model, you measure the running time of an algorithm by counting the number of steps an algorithm takes on a given input.
                Despite the simplifying assumptions made by the RAM model, it works well in practice.
            </p>

            <h3 class="h3 mb-3">Best, worst, and average-case complexity</h3>
            <p class="lead">
                Often, an algorithm’s input determines the number of steps the algorithm takes to run.
                For a given input <strong>n</strong>:
            </p>

            <ul>
                <li class="lead">The <strong>best-case complexity</strong> is the minimum number of steps taken to complete.</li>
                <li class="lead">The <strong>worst-case complexity</strong> is the maximum number of steps taken to complete.</li>
                <li class="lead">The <strong>average-case complexity</strong> is the average number of steps taken to complete.</li>
            </ul>

            <p class="lead">
                Each of these complexities defines a numerical function that represents time vs problem size.
                For example, for an input of size n , an algorithm takes 2n steps to complete in the worst case.
                The worst-case function for time complexity here is T(n)=2n.
                <figure class="text-center">
                    <img src="images/tc.svg" class="img-fluid w-25 rounded shadow-sm">
                    <figcaption class="text-muted mt-3">A graph of T(n)=2n.</figcaption>
                </figure>
            </p>

            <p class="lead">
                <strong>Worst-case complexity</strong> is normally the most useful measure.
                This is because the best-case is often so unlikely that it isn’t beneficial to think about.
                The average-case can be useful, but it is usually difficult to determine. The worst-case is both likely to happen, and easy to calculate.
            </p>

            <h3 class="h3 mb-3">Big O notation</h3>
            <p class="lead">
                Big O is a mathematical notation that describes the limiting behavior of a function as its input tends towards infinity.
                Big O is useful in algorithm analysis because the functions that we get from counting steps often require a lot of detail to specify.
                For example, a worst-case analysis might produce a function like this:
            </p>

            <div class="example-container mb-4">
                <div class="example">
                    <p class="text-center"><code>T(n)=1234n²+1228n+92log₂n+8736</code></p>
                </div>
            </div>

            <p class="lead">
                In reality, this level of detail is not much more informative than stating that “the time grows quadratically with n”.
                It is easier to instead compare the upper and lower bounds of time-complexity functions with asymptotic notation.
                This includes <strong>big O</strong>, <strong>big omega</strong>, and <strong>big theta</strong>.
            </p>

            <figure class="text-center">
                <img src="images/bounds.svg" class="img-fluid w-25 rounded shadow-sm">
                <figcaption class="text-muted mt-3">Upper and lower bounds for n > n0.</figcaption>
            </figure>

            <p class="lead">
                <strong>Big O</strong> describes the upper bound on a function  f.
                f(n)=O(g(n))  means  c⋅g(n) is an upper bound on  f(n).
                There exists some constant c such that f(n) is always ≤c⋅g(n) for large enough n (i.e., n≥n0 for some constant n0).

                Big O notation ignores multiplicative constants.
                In big O analysis, <b>f(n)=n and g(n)=2n</b> are identical.
            </p>

            <p class="lead">
                <strong>Big omega</strong> describes the lower bound on a function.
                f(n)=Ω(g(n)) means  c⋅g(n) is a lower bound on f(n).
                There exists some constant  c such that  f(n) is always ≥c⋅g(n), for all  n≥n0
            </p>

            <p class="lead">
                <strong>Big theta</strong> defines a tight bound where a function f is bound both above and below.
                f(n)=Θ(g(n))  means  c1⋅g(n) is an upper bound on  f(n) and c2⋅g(n) is a lower bound on f(n), for all  n≥n0.
                There exist constants  c1 and  c2  such that f(n)≤ c1⋅g(n) and  f(n)≥ c2⋅g(n).
                This means that g(n) provides a tight bound on f(n)
            </p>

            <h3 class="h3 mb-3">Growth rates and dominance relations</h3>
            <p class="lead">
                Big O notation creates classes of functions, where all functions in a class are equivalent in big O analysis.
                There are a few classes that must be taken in mind:
            </p>

            <div class="container mt-5">
                <!-- Time Complexity Table -->
                <div class="table-responsive">
                    <table class="table table-bordered table-hover complexity-table">
                        <thead class="table-dark">
                            <tr>
                                <th>Notation</th>
                                <th>Name</th>
                                <th>Description</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>O(1)</td>
                                <td>Constant</td>
                                <td>No matter the size of the input, the algorithm will take the same amount of time to complete.</td>
                            </tr>
                            <tr>
                                <td>O(log n)</td>
                                <td>Logarithmic</td>
                                <td>
                                    The time grows linearly with the input size, such as iterating through an array.
                                </td>
                            </tr>
                            <tr>
                                <td>O(n)</td>
                                <td>Linear</td>
                                <td>
                                    Linear algorithms grow linearly with n. For example an algorithm to calculate the exponent of a number by multiplying a value n times in a loop.
                                </td>
                            </tr>
                            <tr>
                                <td>O(n log n)</td>
                                <td>Superlinear</td>
                                <td>
                                    Superlinear algorithms grow just a little faster than linear algorithms. Common sorting algorithms like Mergesort and Quicksort run in superlinear time.
                                </td>
                            </tr>
                            <tr>
                                <td>O(n²)</td>
                                <td>Quadratic</td>
                                <td>
                                    Quadratic algorithms run slowly. An example is an algorithm that checks for duplicates in an array by looping over each element, and then looping over every other element to check for matches.
                                </td>
                            </tr>
                            <tr>
                                <td>O(2<sup>n</sup>)</td>
                                <td>Exponential</td>
                                <td>
                                    Exponential algorithms are very slow. An example is a recursive algorithm to find the nth term of the fibonacci sequence.
                                </td>
                            </tr>
                            <tr>
                                <td>O(n!)</td>
                                <td>Factorial</td>
                                <td>
                                    Factorial algorithms quickly become useless. They occur when generating all permutations of n.
                                </td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>

            <br>
            <figure class="text-center">
                <img src="images/complex.png" class="img-fluid w-25 rounded shadow-sm">
                <figcaption class="text-muted mt-3">Fundamental function's curves.</figcaption>
            </figure>
        </section>

        <section id="exercises" class="mb-5">
            <h2 class="h2 mb-3">It's Evaluation Time!</h2>

            <p class="lead">
                The theoretical program of this section spans over the concept of algorithm and its time complexity.
                We introduced time complexity asymptotic notation and we simultaneously defined how to measure time complexity from pseudo code.
                Evaluating the knowledge developed on those topics requires to understand in depth the main pitfalls.
            </p>

            <ul class="lead">
                <li>
                    It is pretty common that students struggle in front of functions and mathematical concepts.
                </li>
                <li>
                    Another pretty common challenge is to understand loops and incrementally more complex code time Complexities.
                </li>
            </ul>

            <p class="lead">
                PS: not all the students fall on the same errors.
                Therefore, follow my guidelines but follow mostly your class.
            </p>

            <h3 class="h3 mb-3">Example 1</h3>
            <!-- asymptotic proof -->
            <p class="lead">
                One of the most common exercise is the following, given a statement, like <b>2<sup>3n+3</sup>∈ O(2<sup>n</sup>)</b>, prove or disprove it.
            </p>

            <p class="lead">
                In order to solve this type of exercise, it is necessary to apply the definition of asymptotic time complexity, and solve the inequalities in order to find the values of c1 and n0 such that the definition holds (or verify that there is no value for which the definition holds).
            </p>
            <p class="lead">
                2<sup>3n+3</sup>∈ O(2<sup>n</sup>)
            </p>
            <p class="lead">
                2<sup>3n+3</sup> ≤ c<sub>1</sub> 2<sup>n</sup>
            </p>
            <p class="lead">
                2<sup>n</sup>·2<sup>n</sup>·2<sup>n+3</sup> ≤ c<sub>1</sub> 2<sup>n</sup>
            </p>
            <p class="lead">
                2<sup>n</sup>·2<sup>n+3</sup>≤ c<sub>1</sub>
            </p>
            <p class="lead">
                <strong>There is not any costant c<sub>1</sub> greater than a monotonic ascending function.</strong>
            </p>

            <h3 class="h3 mb-3">Example 2</h3>
            <!-- order functions -->
            <p class="lead">
                Sort the following functions from the slowest up to the fastest.
            </p>
            <ul class="lead">
                <li>2 <sup>log<sub>2</sub><span>&#8730;</span>n</sup> </li>
                <li>2 <sup>n/2</sup></li>
                <li>8 <sup>log<sub>4</sub>n</sup></li>
            </ul>
            <p class="lead">Let's monging a little bit the three functions:</p>
            <ul class="lead">
                <li>2 <sup>log<sub>2</sub><span>&#8730;</span>n</sup> = 2 <sup>1/2 log<sub>2</sub>n</sup> = n <sup>1/2 log<sub>2</sub>2 </sup> = <span>&#8730;</span>n </li>
                <li>2 <sup>n/2</sup></li>
                <li>8 <sup>log<sub>4</sub>n</sup> = 2 <sup>3log<sub>4</sub>n</sup>=n<sup>3/2</sup></li>
            </ul>
            <p class="lead">
                Therefore the order is 2 <sup>n/2</sup> then n<sup>3/2</sup> and finally  <span>&#8730;</span>n
            </p>
            <h3 class="h3 mb-3">Example 3</h3>
            <!-- snippets complexity -->
            <p class="lead">
                Study the time complexity of the following snippet of code finding an upper bound for its running time.
            </p>
            <div class="example-container mb-4">
                <div class="example">
                    <p class="text-left"><code>def Pippo(){</code></p>
                    <p class="text-left"><code>    k=7;{</code></p>
                    <p class="text-left"><code>    while k < n {</code></p>
                    <p class="text-left"><code>        k = k * 7;}</code></p>
                    <p class="text-left"><code>return}</code></p>
                </div>
            </div>

            <p class="lead">
                In this case, the execercise requires us to count with respect to the input size n, the asymptotic bound that limits above the
                snippet of code complexity.
                We observe that the while loop ends once k is greater or equal to n.
                So a good practice is track the evolution of k step by step.
                We notice that at the first iteration k=7, at second k=7*7, third k=7*7*7, so at the i-th k=7<sup>i</sup>.
            </p>
            <p class="lead">
                From above we can count how many steps by solving the inequality:
            </p>
            <p class="lead">
                7<sup>i</sup> >= n = i log 7 >= log n
            </p>
            <p class="lead">
                <strong>The time complexity of Pippo() is O(log n)</strong>.
            </p>
        </section>
        <div class="container text-center">
            <button class="btn btn-primary lesson-btn" onclick="window.location.href='index.html'">Return to Home</button>
        </div>
    </main>

    <footer class="text-center mt-5 py-4 bg-light">
        <p class="text-muted">&copy; 2024 Didattica degli Algoritmi.   </p>
    </footer>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha3/dist/js/bootstrap.bundle.min.js"></script>
   <script src="js/script.js"></script>
   <script src="js/plot.js"></script>
</body>
</html>
